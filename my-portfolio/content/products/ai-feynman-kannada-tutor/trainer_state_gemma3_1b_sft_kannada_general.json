{
  "best_global_step": 80,
  "best_metric": 2.9115195274353027,
  "best_model_checkpoint": "outputs/checkpoint-80",
  "epoch": 0.625,
  "eval_steps": 5,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0078125,
      "grad_norm": 6.022777080535889,
      "learning_rate": 0.0,
      "loss": 4.709,
      "step": 1
    },
    {
      "epoch": 0.015625,
      "grad_norm": 5.522542476654053,
      "learning_rate": 1e-05,
      "loss": 4.645,
      "step": 2
    },
    {
      "epoch": 0.0234375,
      "grad_norm": 6.228818893432617,
      "learning_rate": 2e-05,
      "loss": 4.6689,
      "step": 3
    },
    {
      "epoch": 0.03125,
      "grad_norm": 3.930680751800537,
      "learning_rate": 3e-05,
      "loss": 4.2994,
      "step": 4
    },
    {
      "epoch": 0.0390625,
      "grad_norm": 4.139946460723877,
      "learning_rate": 4e-05,
      "loss": 4.2931,
      "step": 5
    },
    {
      "epoch": 0.0390625,
      "eval_loss": 3.9897301197052,
      "eval_runtime": 23.1316,
      "eval_samples_per_second": 2.767,
      "eval_steps_per_second": 0.692,
      "step": 5
    },
    {
      "epoch": 0.046875,
      "grad_norm": 2.721674919128418,
      "learning_rate": 5e-05,
      "loss": 3.9482,
      "step": 6
    },
    {
      "epoch": 0.0546875,
      "grad_norm": 2.2166316509246826,
      "learning_rate": 4.666666666666667e-05,
      "loss": 3.8375,
      "step": 7
    },
    {
      "epoch": 0.0625,
      "grad_norm": 2.5172765254974365,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 3.7624,
      "step": 8
    },
    {
      "epoch": 0.0703125,
      "grad_norm": 2.3355166912078857,
      "learning_rate": 4e-05,
      "loss": 3.6947,
      "step": 9
    },
    {
      "epoch": 0.078125,
      "grad_norm": 2.1575851440429688,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 3.8004,
      "step": 10
    },
    {
      "epoch": 0.078125,
      "eval_loss": 3.5579686164855957,
      "eval_runtime": 18.1823,
      "eval_samples_per_second": 3.52,
      "eval_steps_per_second": 0.88,
      "step": 10
    },
    {
      "epoch": 0.0859375,
      "grad_norm": 1.8085198402404785,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 3.5552,
      "step": 11
    },
    {
      "epoch": 0.09375,
      "grad_norm": 1.8999933004379272,
      "learning_rate": 3e-05,
      "loss": 3.6481,
      "step": 12
    },
    {
      "epoch": 0.1015625,
      "grad_norm": 1.6743087768554688,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 3.6942,
      "step": 13
    },
    {
      "epoch": 0.109375,
      "grad_norm": 1.5521196126937866,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 3.549,
      "step": 14
    },
    {
      "epoch": 0.1171875,
      "grad_norm": 1.448380708694458,
      "learning_rate": 2e-05,
      "loss": 3.3497,
      "step": 15
    },
    {
      "epoch": 0.1171875,
      "eval_loss": 3.3961822986602783,
      "eval_runtime": 18.4131,
      "eval_samples_per_second": 3.476,
      "eval_steps_per_second": 0.869,
      "step": 15
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.2122657299041748,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 3.1874,
      "step": 16
    },
    {
      "epoch": 0.1328125,
      "grad_norm": 1.2194730043411255,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 3.2959,
      "step": 17
    },
    {
      "epoch": 0.140625,
      "grad_norm": 1.334502935409546,
      "learning_rate": 1e-05,
      "loss": 3.3143,
      "step": 18
    },
    {
      "epoch": 0.1484375,
      "grad_norm": 1.2793991565704346,
      "learning_rate": 6.666666666666667e-06,
      "loss": 3.2323,
      "step": 19
    },
    {
      "epoch": 0.15625,
      "grad_norm": 1.2542752027511597,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 3.3902,
      "step": 20
    },
    {
      "epoch": 0.15625,
      "eval_loss": 3.3427839279174805,
      "eval_runtime": 19.129,
      "eval_samples_per_second": 3.346,
      "eval_steps_per_second": 0.836,
      "step": 20
    },
    {
      "epoch": 0.1640625,
      "grad_norm": 1.1812304258346558,
      "learning_rate": 0.0,
      "loss": 3.4294,
      "step": 21
    },
    {
      "epoch": 0.171875,
      "grad_norm": 1.1202501058578491,
      "learning_rate": 2.714285714285714e-05,
      "loss": 3.3583,
      "step": 22
    },
    {
      "epoch": 0.1796875,
      "grad_norm": 1.2101426124572754,
      "learning_rate": 2.5714285714285714e-05,
      "loss": 3.2497,
      "step": 23
    },
    {
      "epoch": 0.1875,
      "grad_norm": 1.431541919708252,
      "learning_rate": 2.4285714285714288e-05,
      "loss": 3.2644,
      "step": 24
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 1.3201135396957397,
      "learning_rate": 2.2857142857142858e-05,
      "loss": 3.3994,
      "step": 25
    },
    {
      "epoch": 0.1953125,
      "eval_loss": 3.248140335083008,
      "eval_runtime": 14.9285,
      "eval_samples_per_second": 4.287,
      "eval_steps_per_second": 1.072,
      "step": 25
    },
    {
      "epoch": 0.203125,
      "grad_norm": 1.0026397705078125,
      "learning_rate": 2.1428571428571428e-05,
      "loss": 3.3304,
      "step": 26
    },
    {
      "epoch": 0.2109375,
      "grad_norm": 1.0672863721847534,
      "learning_rate": 2e-05,
      "loss": 3.1579,
      "step": 27
    },
    {
      "epoch": 0.21875,
      "grad_norm": 1.2539173364639282,
      "learning_rate": 1.8571428571428572e-05,
      "loss": 3.3491,
      "step": 28
    },
    {
      "epoch": 0.2265625,
      "grad_norm": 0.9356549978256226,
      "learning_rate": 1.7142857142857145e-05,
      "loss": 3.1397,
      "step": 29
    },
    {
      "epoch": 0.234375,
      "grad_norm": 1.1043522357940674,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 3.26,
      "step": 30
    },
    {
      "epoch": 0.234375,
      "eval_loss": 3.1774516105651855,
      "eval_runtime": 21.6803,
      "eval_samples_per_second": 2.952,
      "eval_steps_per_second": 0.738,
      "step": 30
    },
    {
      "epoch": 0.2421875,
      "grad_norm": 1.7227206230163574,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 3.125,
      "step": 31
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.9862483739852905,
      "learning_rate": 1.2857142857142857e-05,
      "loss": 3.0529,
      "step": 32
    },
    {
      "epoch": 0.2578125,
      "grad_norm": 1.384766697883606,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 3.336,
      "step": 33
    },
    {
      "epoch": 0.265625,
      "grad_norm": 1.131961703300476,
      "learning_rate": 1e-05,
      "loss": 2.9918,
      "step": 34
    },
    {
      "epoch": 0.2734375,
      "grad_norm": 0.9418822526931763,
      "learning_rate": 8.571428571428573e-06,
      "loss": 3.1463,
      "step": 35
    },
    {
      "epoch": 0.2734375,
      "eval_loss": 3.1396167278289795,
      "eval_runtime": 20.6075,
      "eval_samples_per_second": 3.106,
      "eval_steps_per_second": 0.776,
      "step": 35
    },
    {
      "epoch": 0.28125,
      "grad_norm": 0.9521081447601318,
      "learning_rate": 7.142857142857143e-06,
      "loss": 3.0166,
      "step": 36
    },
    {
      "epoch": 0.2890625,
      "grad_norm": 1.1084630489349365,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 3.2786,
      "step": 37
    },
    {
      "epoch": 0.296875,
      "grad_norm": 0.9952656626701355,
      "learning_rate": 4.285714285714286e-06,
      "loss": 3.1258,
      "step": 38
    },
    {
      "epoch": 0.3046875,
      "grad_norm": 0.9240100979804993,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 3.0017,
      "step": 39
    },
    {
      "epoch": 0.3125,
      "grad_norm": 1.093039870262146,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 3.2625,
      "step": 40
    },
    {
      "epoch": 0.3125,
      "eval_loss": 3.124809741973877,
      "eval_runtime": 19.6928,
      "eval_samples_per_second": 3.25,
      "eval_steps_per_second": 0.812,
      "step": 40
    },
    {
      "epoch": 0.3203125,
      "grad_norm": 2.891834259033203,
      "learning_rate": 0.0,
      "loss": 2.9909,
      "step": 41
    },
    {
      "epoch": 0.328125,
      "grad_norm": 1.3242634534835815,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 2.9992,
      "step": 42
    },
    {
      "epoch": 0.3359375,
      "grad_norm": 0.8459686636924744,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 2.7952,
      "step": 43
    },
    {
      "epoch": 0.34375,
      "grad_norm": 1.0331029891967773,
      "learning_rate": 2.466666666666667e-05,
      "loss": 2.9421,
      "step": 44
    },
    {
      "epoch": 0.3515625,
      "grad_norm": 1.3809571266174316,
      "learning_rate": 2.4e-05,
      "loss": 2.8816,
      "step": 45
    },
    {
      "epoch": 0.3515625,
      "eval_loss": 3.0693252086639404,
      "eval_runtime": 18.9264,
      "eval_samples_per_second": 3.382,
      "eval_steps_per_second": 0.845,
      "step": 45
    },
    {
      "epoch": 0.359375,
      "grad_norm": 0.9477461576461792,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 3.0542,
      "step": 46
    },
    {
      "epoch": 0.3671875,
      "grad_norm": 1.029321312904358,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 3.0802,
      "step": 47
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.00047767162323,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 3.2089,
      "step": 48
    },
    {
      "epoch": 0.3828125,
      "grad_norm": 1.2502232789993286,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 3.0278,
      "step": 49
    },
    {
      "epoch": 0.390625,
      "grad_norm": 0.9463300704956055,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 3.0327,
      "step": 50
    },
    {
      "epoch": 0.390625,
      "eval_loss": 3.0195844173431396,
      "eval_runtime": 21.6429,
      "eval_samples_per_second": 2.957,
      "eval_steps_per_second": 0.739,
      "step": 50
    },
    {
      "epoch": 0.3984375,
      "grad_norm": 1.0209457874298096,
      "learning_rate": 2e-05,
      "loss": 3.0024,
      "step": 51
    },
    {
      "epoch": 0.40625,
      "grad_norm": 0.997304379940033,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 3.0123,
      "step": 52
    },
    {
      "epoch": 0.4140625,
      "grad_norm": 0.8114755749702454,
      "learning_rate": 1.866666666666667e-05,
      "loss": 3.1327,
      "step": 53
    },
    {
      "epoch": 0.421875,
      "grad_norm": 0.9838560819625854,
      "learning_rate": 1.8e-05,
      "loss": 3.175,
      "step": 54
    },
    {
      "epoch": 0.4296875,
      "grad_norm": 1.9061492681503296,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 2.9921,
      "step": 55
    },
    {
      "epoch": 0.4296875,
      "eval_loss": 2.9823343753814697,
      "eval_runtime": 21.1374,
      "eval_samples_per_second": 3.028,
      "eval_steps_per_second": 0.757,
      "step": 55
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.9838432669639587,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 2.9676,
      "step": 56
    },
    {
      "epoch": 0.4453125,
      "grad_norm": 1.0217281579971313,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.0239,
      "step": 57
    },
    {
      "epoch": 0.453125,
      "grad_norm": 1.0637181997299194,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 3.1098,
      "step": 58
    },
    {
      "epoch": 0.4609375,
      "grad_norm": 0.9324243664741516,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 3.1027,
      "step": 59
    },
    {
      "epoch": 0.46875,
      "grad_norm": 1.0750584602355957,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 3.1277,
      "step": 60
    },
    {
      "epoch": 0.46875,
      "eval_loss": 2.955305814743042,
      "eval_runtime": 21.2739,
      "eval_samples_per_second": 3.008,
      "eval_steps_per_second": 0.752,
      "step": 60
    },
    {
      "epoch": 0.4765625,
      "grad_norm": 0.8447233438491821,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 2.8549,
      "step": 61
    },
    {
      "epoch": 0.484375,
      "grad_norm": 0.8827461004257202,
      "learning_rate": 1.2666666666666668e-05,
      "loss": 2.9395,
      "step": 62
    },
    {
      "epoch": 0.4921875,
      "grad_norm": 0.922441303730011,
      "learning_rate": 1.2e-05,
      "loss": 2.8073,
      "step": 63
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.847958505153656,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 2.932,
      "step": 64
    },
    {
      "epoch": 0.5078125,
      "grad_norm": 1.0326042175292969,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 2.8793,
      "step": 65
    },
    {
      "epoch": 0.5078125,
      "eval_loss": 2.9367966651916504,
      "eval_runtime": 18.7581,
      "eval_samples_per_second": 3.412,
      "eval_steps_per_second": 0.853,
      "step": 65
    },
    {
      "epoch": 0.515625,
      "grad_norm": 0.8918312788009644,
      "learning_rate": 1e-05,
      "loss": 3.156,
      "step": 66
    },
    {
      "epoch": 0.5234375,
      "grad_norm": 0.9410416483879089,
      "learning_rate": 9.333333333333334e-06,
      "loss": 2.8548,
      "step": 67
    },
    {
      "epoch": 0.53125,
      "grad_norm": 0.9545173645019531,
      "learning_rate": 8.666666666666668e-06,
      "loss": 3.1067,
      "step": 68
    },
    {
      "epoch": 0.5390625,
      "grad_norm": 0.9259741902351379,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.8469,
      "step": 69
    },
    {
      "epoch": 0.546875,
      "grad_norm": 0.8848594427108765,
      "learning_rate": 7.333333333333334e-06,
      "loss": 3.0876,
      "step": 70
    },
    {
      "epoch": 0.546875,
      "eval_loss": 2.9232966899871826,
      "eval_runtime": 17.6854,
      "eval_samples_per_second": 3.619,
      "eval_steps_per_second": 0.905,
      "step": 70
    },
    {
      "epoch": 0.5546875,
      "grad_norm": 0.8618075251579285,
      "learning_rate": 6.666666666666667e-06,
      "loss": 3.1544,
      "step": 71
    },
    {
      "epoch": 0.5625,
      "grad_norm": 1.2319494485855103,
      "learning_rate": 6e-06,
      "loss": 3.0326,
      "step": 72
    },
    {
      "epoch": 0.5703125,
      "grad_norm": 0.8558410406112671,
      "learning_rate": 5.333333333333334e-06,
      "loss": 2.9812,
      "step": 73
    },
    {
      "epoch": 0.578125,
      "grad_norm": 1.1056996583938599,
      "learning_rate": 4.666666666666667e-06,
      "loss": 2.9815,
      "step": 74
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 1.5109761953353882,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.8539,
      "step": 75
    },
    {
      "epoch": 0.5859375,
      "eval_loss": 2.9149982929229736,
      "eval_runtime": 18.2603,
      "eval_samples_per_second": 3.505,
      "eval_steps_per_second": 0.876,
      "step": 75
    },
    {
      "epoch": 0.59375,
      "grad_norm": 0.925497829914093,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 3.1835,
      "step": 76
    },
    {
      "epoch": 0.6015625,
      "grad_norm": 0.994988203048706,
      "learning_rate": 2.666666666666667e-06,
      "loss": 2.9797,
      "step": 77
    },
    {
      "epoch": 0.609375,
      "grad_norm": 1.4680826663970947,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 2.9876,
      "step": 78
    },
    {
      "epoch": 0.6171875,
      "grad_norm": 0.7601104378700256,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 3.0467,
      "step": 79
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.9181073904037476,
      "learning_rate": 6.666666666666667e-07,
      "loss": 2.8981,
      "step": 80
    },
    {
      "epoch": 0.625,
      "eval_loss": 2.9115195274353027,
      "eval_runtime": 14.9563,
      "eval_samples_per_second": 4.279,
      "eval_steps_per_second": 1.07,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 80,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 5,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.5358272761135104e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
