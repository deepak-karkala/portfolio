{
  "best_global_step": 90,
  "best_metric": 2.473759174346924,
  "best_model_checkpoint": "outputs_sft_phy/checkpoint-90",
  "epoch": 0.9498680738786279,
  "eval_steps": 10,
  "global_step": 90,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010554089709762533,
      "grad_norm": 2.433727502822876,
      "learning_rate": 0.0,
      "loss": 3.2475,
      "step": 1
    },
    {
      "epoch": 0.021108179419525065,
      "grad_norm": 2.4750819206237793,
      "learning_rate": 1e-05,
      "loss": 3.3766,
      "step": 2
    },
    {
      "epoch": 0.0316622691292876,
      "grad_norm": 1.8418415784835815,
      "learning_rate": 2e-05,
      "loss": 3.1603,
      "step": 3
    },
    {
      "epoch": 0.04221635883905013,
      "grad_norm": 1.7607852220535278,
      "learning_rate": 3e-05,
      "loss": 3.1578,
      "step": 4
    },
    {
      "epoch": 0.052770448548812667,
      "grad_norm": 1.7178648710250854,
      "learning_rate": 4e-05,
      "loss": 3.199,
      "step": 5
    },
    {
      "epoch": 0.0633245382585752,
      "grad_norm": 1.5186363458633423,
      "learning_rate": 5e-05,
      "loss": 3.0122,
      "step": 6
    },
    {
      "epoch": 0.07387862796833773,
      "grad_norm": 1.316882848739624,
      "learning_rate": 4.909090909090909e-05,
      "loss": 3.0157,
      "step": 7
    },
    {
      "epoch": 0.08443271767810026,
      "grad_norm": 1.5950262546539307,
      "learning_rate": 4.8181818181818186e-05,
      "loss": 2.9839,
      "step": 8
    },
    {
      "epoch": 0.09498680738786279,
      "grad_norm": 1.3065601587295532,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 2.9949,
      "step": 9
    },
    {
      "epoch": 0.10554089709762533,
      "grad_norm": 1.1956150531768799,
      "learning_rate": 4.636363636363636e-05,
      "loss": 2.9368,
      "step": 10
    },
    {
      "epoch": 0.10554089709762533,
      "eval_loss": 2.8818068504333496,
      "eval_runtime": 20.2249,
      "eval_samples_per_second": 3.164,
      "eval_steps_per_second": 0.791,
      "step": 10
    },
    {
      "epoch": 0.11609498680738786,
      "grad_norm": 1.8549222946166992,
      "learning_rate": 4.545454545454546e-05,
      "loss": 2.9639,
      "step": 11
    },
    {
      "epoch": 0.1266490765171504,
      "grad_norm": 1.1433498859405518,
      "learning_rate": 4.454545454545455e-05,
      "loss": 2.8964,
      "step": 12
    },
    {
      "epoch": 0.13720316622691292,
      "grad_norm": 0.9854563474655151,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 2.8344,
      "step": 13
    },
    {
      "epoch": 0.14775725593667546,
      "grad_norm": 1.1302911043167114,
      "learning_rate": 4.2727272727272724e-05,
      "loss": 2.8999,
      "step": 14
    },
    {
      "epoch": 0.158311345646438,
      "grad_norm": 1.127582311630249,
      "learning_rate": 4.181818181818182e-05,
      "loss": 2.7745,
      "step": 15
    },
    {
      "epoch": 0.16886543535620052,
      "grad_norm": 1.007265329360962,
      "learning_rate": 4.0909090909090915e-05,
      "loss": 2.7668,
      "step": 16
    },
    {
      "epoch": 0.17941952506596306,
      "grad_norm": 1.1262568235397339,
      "learning_rate": 4e-05,
      "loss": 2.8016,
      "step": 17
    },
    {
      "epoch": 0.18997361477572558,
      "grad_norm": 0.9738558530807495,
      "learning_rate": 3.909090909090909e-05,
      "loss": 2.7332,
      "step": 18
    },
    {
      "epoch": 0.20052770448548812,
      "grad_norm": 0.9846770167350769,
      "learning_rate": 3.818181818181819e-05,
      "loss": 2.6945,
      "step": 19
    },
    {
      "epoch": 0.21108179419525067,
      "grad_norm": 1.0000431537628174,
      "learning_rate": 3.7272727272727276e-05,
      "loss": 2.6663,
      "step": 20
    },
    {
      "epoch": 0.21108179419525067,
      "eval_loss": 2.7012219429016113,
      "eval_runtime": 24.6133,
      "eval_samples_per_second": 2.6,
      "eval_steps_per_second": 0.65,
      "step": 20
    },
    {
      "epoch": 0.22163588390501318,
      "grad_norm": 0.9631907939910889,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 2.7134,
      "step": 21
    },
    {
      "epoch": 0.23218997361477572,
      "grad_norm": 0.9070726037025452,
      "learning_rate": 3.545454545454546e-05,
      "loss": 2.7958,
      "step": 22
    },
    {
      "epoch": 0.24274406332453827,
      "grad_norm": 1.0329550504684448,
      "learning_rate": 3.454545454545455e-05,
      "loss": 2.6809,
      "step": 23
    },
    {
      "epoch": 0.2532981530343008,
      "grad_norm": 0.9879037737846375,
      "learning_rate": 3.3636363636363636e-05,
      "loss": 2.7536,
      "step": 24
    },
    {
      "epoch": 0.2638522427440633,
      "grad_norm": 1.0245832204818726,
      "learning_rate": 3.272727272727273e-05,
      "loss": 2.6121,
      "step": 25
    },
    {
      "epoch": 0.27440633245382584,
      "grad_norm": 0.9349443912506104,
      "learning_rate": 3.181818181818182e-05,
      "loss": 2.6402,
      "step": 26
    },
    {
      "epoch": 0.2849604221635884,
      "grad_norm": 0.9854416251182556,
      "learning_rate": 3.090909090909091e-05,
      "loss": 2.614,
      "step": 27
    },
    {
      "epoch": 0.2955145118733509,
      "grad_norm": 1.0137927532196045,
      "learning_rate": 3e-05,
      "loss": 2.5924,
      "step": 28
    },
    {
      "epoch": 0.30606860158311344,
      "grad_norm": 0.9923598766326904,
      "learning_rate": 2.909090909090909e-05,
      "loss": 2.5709,
      "step": 29
    },
    {
      "epoch": 0.316622691292876,
      "grad_norm": 1.0542845726013184,
      "learning_rate": 2.818181818181818e-05,
      "loss": 2.585,
      "step": 30
    },
    {
      "epoch": 0.316622691292876,
      "eval_loss": 2.6092631816864014,
      "eval_runtime": 22.9563,
      "eval_samples_per_second": 2.788,
      "eval_steps_per_second": 0.697,
      "step": 30
    },
    {
      "epoch": 0.32717678100263853,
      "grad_norm": 1.0004009008407593,
      "learning_rate": 2.7272727272727273e-05,
      "loss": 2.5583,
      "step": 31
    },
    {
      "epoch": 0.33773087071240104,
      "grad_norm": 0.8647028803825378,
      "learning_rate": 2.636363636363636e-05,
      "loss": 2.7292,
      "step": 32
    },
    {
      "epoch": 0.3482849604221636,
      "grad_norm": 0.8793551325798035,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 2.6655,
      "step": 33
    },
    {
      "epoch": 0.35883905013192613,
      "grad_norm": 3.6418776512145996,
      "learning_rate": 2.4545454545454545e-05,
      "loss": 2.5804,
      "step": 34
    },
    {
      "epoch": 0.36939313984168864,
      "grad_norm": 0.9767493605613708,
      "learning_rate": 2.3636363636363637e-05,
      "loss": 2.53,
      "step": 35
    },
    {
      "epoch": 0.37994722955145116,
      "grad_norm": 1.0698555707931519,
      "learning_rate": 2.272727272727273e-05,
      "loss": 2.687,
      "step": 36
    },
    {
      "epoch": 0.39050131926121373,
      "grad_norm": 1.1536203622817993,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 2.6094,
      "step": 37
    },
    {
      "epoch": 0.40105540897097625,
      "grad_norm": 0.852760374546051,
      "learning_rate": 2.090909090909091e-05,
      "loss": 2.6192,
      "step": 38
    },
    {
      "epoch": 0.41160949868073876,
      "grad_norm": 0.8197137713432312,
      "learning_rate": 2e-05,
      "loss": 2.6269,
      "step": 39
    },
    {
      "epoch": 0.42216358839050133,
      "grad_norm": 0.875173032283783,
      "learning_rate": 1.9090909090909094e-05,
      "loss": 2.5661,
      "step": 40
    },
    {
      "epoch": 0.42216358839050133,
      "eval_loss": 2.555778980255127,
      "eval_runtime": 25.6894,
      "eval_samples_per_second": 2.491,
      "eval_steps_per_second": 0.623,
      "step": 40
    },
    {
      "epoch": 0.43271767810026385,
      "grad_norm": 0.8511638641357422,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 2.4929,
      "step": 41
    },
    {
      "epoch": 0.44327176781002636,
      "grad_norm": 0.8458951711654663,
      "learning_rate": 1.7272727272727274e-05,
      "loss": 2.6087,
      "step": 42
    },
    {
      "epoch": 0.45382585751978893,
      "grad_norm": 0.8204021453857422,
      "learning_rate": 1.6363636363636366e-05,
      "loss": 2.5637,
      "step": 43
    },
    {
      "epoch": 0.46437994722955145,
      "grad_norm": 0.9202430844306946,
      "learning_rate": 1.5454545454545454e-05,
      "loss": 2.4931,
      "step": 44
    },
    {
      "epoch": 0.47493403693931396,
      "grad_norm": 0.7845017313957214,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 2.6045,
      "step": 45
    },
    {
      "epoch": 0.48548812664907653,
      "grad_norm": 0.8319498896598816,
      "learning_rate": 1.3636363636363637e-05,
      "loss": 2.6592,
      "step": 46
    },
    {
      "epoch": 0.49604221635883905,
      "grad_norm": 0.8271086812019348,
      "learning_rate": 1.2727272727272727e-05,
      "loss": 2.5141,
      "step": 47
    },
    {
      "epoch": 0.5065963060686016,
      "grad_norm": 0.9768878817558289,
      "learning_rate": 1.1818181818181819e-05,
      "loss": 2.5875,
      "step": 48
    },
    {
      "epoch": 0.5171503957783641,
      "grad_norm": 1.0991734266281128,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 2.5483,
      "step": 49
    },
    {
      "epoch": 0.5277044854881267,
      "grad_norm": 1.6193912029266357,
      "learning_rate": 1e-05,
      "loss": 2.4718,
      "step": 50
    },
    {
      "epoch": 0.5277044854881267,
      "eval_loss": 2.5256705284118652,
      "eval_runtime": 25.0993,
      "eval_samples_per_second": 2.55,
      "eval_steps_per_second": 0.637,
      "step": 50
    },
    {
      "epoch": 0.5382585751978892,
      "grad_norm": 1.6662992238998413,
      "learning_rate": 9.090909090909091e-06,
      "loss": 2.5073,
      "step": 51
    },
    {
      "epoch": 0.5488126649076517,
      "grad_norm": 0.84674471616745,
      "learning_rate": 8.181818181818183e-06,
      "loss": 2.4834,
      "step": 52
    },
    {
      "epoch": 0.5593667546174143,
      "grad_norm": 0.7830759286880493,
      "learning_rate": 7.272727272727272e-06,
      "loss": 2.5501,
      "step": 53
    },
    {
      "epoch": 0.5699208443271768,
      "grad_norm": 0.7456364631652832,
      "learning_rate": 6.363636363636363e-06,
      "loss": 2.5679,
      "step": 54
    },
    {
      "epoch": 0.5804749340369393,
      "grad_norm": 0.8076890110969543,
      "learning_rate": 5.4545454545454545e-06,
      "loss": 2.5858,
      "step": 55
    },
    {
      "epoch": 0.5910290237467019,
      "grad_norm": 0.9221899509429932,
      "learning_rate": 4.5454545454545455e-06,
      "loss": 2.5663,
      "step": 56
    },
    {
      "epoch": 0.6015831134564644,
      "grad_norm": 0.7643054723739624,
      "learning_rate": 3.636363636363636e-06,
      "loss": 2.5092,
      "step": 57
    },
    {
      "epoch": 0.6121372031662269,
      "grad_norm": 0.8335980772972107,
      "learning_rate": 2.7272727272727272e-06,
      "loss": 2.4996,
      "step": 58
    },
    {
      "epoch": 0.6226912928759895,
      "grad_norm": 0.9139154553413391,
      "learning_rate": 1.818181818181818e-06,
      "loss": 2.4898,
      "step": 59
    },
    {
      "epoch": 0.633245382585752,
      "grad_norm": 1.0631884336471558,
      "learning_rate": 9.09090909090909e-07,
      "loss": 2.6223,
      "step": 60
    },
    {
      "epoch": 0.633245382585752,
      "eval_loss": 2.51566743850708,
      "eval_runtime": 23.8484,
      "eval_samples_per_second": 2.684,
      "eval_steps_per_second": 0.671,
      "step": 60
    },
    {
      "epoch": 0.6437994722955145,
      "grad_norm": 0.9358166456222534,
      "learning_rate": 0.0,
      "loss": 2.575,
      "step": 61
    },
    {
      "epoch": 0.6543535620052771,
      "grad_norm": 0.8250216245651245,
      "learning_rate": 1.7058823529411767e-05,
      "loss": 2.5656,
      "step": 62
    },
    {
      "epoch": 0.6649076517150396,
      "grad_norm": 0.8569040894508362,
      "learning_rate": 1.647058823529412e-05,
      "loss": 2.6272,
      "step": 63
    },
    {
      "epoch": 0.6754617414248021,
      "grad_norm": 0.9090535640716553,
      "learning_rate": 1.588235294117647e-05,
      "loss": 2.4974,
      "step": 64
    },
    {
      "epoch": 0.6860158311345647,
      "grad_norm": 0.8925924897193909,
      "learning_rate": 1.5294117647058826e-05,
      "loss": 2.5432,
      "step": 65
    },
    {
      "epoch": 0.6965699208443272,
      "grad_norm": 0.8578366637229919,
      "learning_rate": 1.4705882352941177e-05,
      "loss": 2.4082,
      "step": 66
    },
    {
      "epoch": 0.7071240105540897,
      "grad_norm": 0.8703818917274475,
      "learning_rate": 1.411764705882353e-05,
      "loss": 2.5646,
      "step": 67
    },
    {
      "epoch": 0.7176781002638523,
      "grad_norm": 0.9795975685119629,
      "learning_rate": 1.3529411764705883e-05,
      "loss": 2.5573,
      "step": 68
    },
    {
      "epoch": 0.7282321899736148,
      "grad_norm": 0.7780184149742126,
      "learning_rate": 1.2941176470588238e-05,
      "loss": 2.5441,
      "step": 69
    },
    {
      "epoch": 0.7387862796833773,
      "grad_norm": 0.9989678859710693,
      "learning_rate": 1.2352941176470589e-05,
      "loss": 2.523,
      "step": 70
    },
    {
      "epoch": 0.7387862796833773,
      "eval_loss": 2.4957480430603027,
      "eval_runtime": 20.3114,
      "eval_samples_per_second": 3.151,
      "eval_steps_per_second": 0.788,
      "step": 70
    },
    {
      "epoch": 0.7493403693931399,
      "grad_norm": 0.9424587488174438,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 2.4805,
      "step": 71
    },
    {
      "epoch": 0.7598944591029023,
      "grad_norm": 0.8827928304672241,
      "learning_rate": 1.1176470588235295e-05,
      "loss": 2.5956,
      "step": 72
    },
    {
      "epoch": 0.7704485488126649,
      "grad_norm": 0.8950329422950745,
      "learning_rate": 1.0588235294117648e-05,
      "loss": 2.5384,
      "step": 73
    },
    {
      "epoch": 0.7810026385224275,
      "grad_norm": 0.9117358326911926,
      "learning_rate": 1e-05,
      "loss": 2.4482,
      "step": 74
    },
    {
      "epoch": 0.7915567282321899,
      "grad_norm": 0.8779691457748413,
      "learning_rate": 9.411764705882354e-06,
      "loss": 2.4817,
      "step": 75
    },
    {
      "epoch": 0.8021108179419525,
      "grad_norm": 0.965211033821106,
      "learning_rate": 8.823529411764707e-06,
      "loss": 2.6026,
      "step": 76
    },
    {
      "epoch": 0.8126649076517151,
      "grad_norm": 0.783396303653717,
      "learning_rate": 8.23529411764706e-06,
      "loss": 2.5098,
      "step": 77
    },
    {
      "epoch": 0.8232189973614775,
      "grad_norm": 0.8775526285171509,
      "learning_rate": 7.647058823529413e-06,
      "loss": 2.4937,
      "step": 78
    },
    {
      "epoch": 0.8337730870712401,
      "grad_norm": 0.7702327370643616,
      "learning_rate": 7.058823529411765e-06,
      "loss": 2.522,
      "step": 79
    },
    {
      "epoch": 0.8443271767810027,
      "grad_norm": 0.8163665533065796,
      "learning_rate": 6.470588235294119e-06,
      "loss": 2.6036,
      "step": 80
    },
    {
      "epoch": 0.8443271767810027,
      "eval_loss": 2.479490041732788,
      "eval_runtime": 24.881,
      "eval_samples_per_second": 2.572,
      "eval_steps_per_second": 0.643,
      "step": 80
    },
    {
      "epoch": 0.8548812664907651,
      "grad_norm": 0.8926342725753784,
      "learning_rate": 5.882352941176471e-06,
      "loss": 2.4916,
      "step": 81
    },
    {
      "epoch": 0.8654353562005277,
      "grad_norm": 0.839670717716217,
      "learning_rate": 5.294117647058824e-06,
      "loss": 2.5116,
      "step": 82
    },
    {
      "epoch": 0.8759894459102903,
      "grad_norm": 0.8997053503990173,
      "learning_rate": 4.705882352941177e-06,
      "loss": 2.4076,
      "step": 83
    },
    {
      "epoch": 0.8865435356200527,
      "grad_norm": 0.7768141031265259,
      "learning_rate": 4.11764705882353e-06,
      "loss": 2.4225,
      "step": 84
    },
    {
      "epoch": 0.8970976253298153,
      "grad_norm": 0.8348098993301392,
      "learning_rate": 3.5294117647058825e-06,
      "loss": 2.4366,
      "step": 85
    },
    {
      "epoch": 0.9076517150395779,
      "grad_norm": 0.8276033997535706,
      "learning_rate": 2.9411764705882355e-06,
      "loss": 2.5079,
      "step": 86
    },
    {
      "epoch": 0.9182058047493403,
      "grad_norm": 0.7912948131561279,
      "learning_rate": 2.3529411764705885e-06,
      "loss": 2.509,
      "step": 87
    },
    {
      "epoch": 0.9287598944591029,
      "grad_norm": 0.7895802855491638,
      "learning_rate": 1.7647058823529412e-06,
      "loss": 2.4378,
      "step": 88
    },
    {
      "epoch": 0.9393139841688655,
      "grad_norm": 0.802466630935669,
      "learning_rate": 1.1764705882352942e-06,
      "loss": 2.5026,
      "step": 89
    },
    {
      "epoch": 0.9498680738786279,
      "grad_norm": 0.8368867039680481,
      "learning_rate": 5.882352941176471e-07,
      "loss": 2.448,
      "step": 90
    },
    {
      "epoch": 0.9498680738786279,
      "eval_loss": 2.473759174346924,
      "eval_runtime": 24.5624,
      "eval_samples_per_second": 2.606,
      "eval_steps_per_second": 0.651,
      "step": 90
    }
  ],
  "logging_steps": 1,
  "max_steps": 90,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.163763632509747e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
